# ğŸ“Š Microservice de MÃ©triques ZenBilling

Microservice autonome dÃ©diÃ© aux mÃ©triques, analytics et reporting pour l'application ZenBilling, offrant des dashboards en temps rÃ©el, KPIs avancÃ©s et gÃ©nÃ©ration de rapports.

## ğŸš€ FonctionnalitÃ©s

### ğŸ“ˆ Dashboard et MÃ©triques
- MÃ©triques en temps rÃ©el des revenus et performances
- KPIs clÃ©s (CA mensuel/annuel, factures en attente, taux de conversion)
- Comparaisons de pÃ©riodes avec calculs de croissance
- Top clients et distribution des statuts
- MÃ©triques de productivitÃ© par utilisateur

### ğŸ“Š Analytics AvancÃ©es
- Analyse des revenus par pÃ©riode (jour, semaine, mois, annÃ©e)
- Analytics clients avec scoring de risque et valeur vie
- Analytics produits avec tendances et conversions
- Analyse de cohortes pour la rÃ©tention client
- PrÃ©visions et modÃ©lisation prÃ©dictive

### ğŸ“‹ Reporting
- GÃ©nÃ©ration de rapports personnalisÃ©s
- Export multi-formats (JSON, CSV, PDF, XLSX)
- Rapports de revenus, clients, produits, taxes
- Planification et envoi automatique par email
- Archivage et historique des rapports

### âš¡ Performance et Cache
- Cache Redis intelligent avec invalidation automatique
- Aggregation de donnÃ©es en arriÃ¨re-plan
- Optimisation des requÃªtes complexes
- MÃ©triques de performance du service

### ğŸ”” Alertes et Monitoring
- SystÃ¨me d'alertes configurable sur mÃ©triques
- Monitoring en temps rÃ©el des KPIs
- Notifications par email sur seuils
- Health checks et diagnostics

## ğŸ—ï¸ Architecture

```
metrics-microservice/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ analytics/           # Moteurs d'analyse avancÃ©e
â”‚   â”œâ”€â”€ aggregators/         # Services d'agrÃ©gation de donnÃ©es
â”‚   â”œâ”€â”€ controllers/         # ContrÃ´leurs API
â”‚   â”œâ”€â”€ services/           # Logique mÃ©tier
â”‚   â”œâ”€â”€ middlewares/        # Middlewares Express
â”‚   â”œâ”€â”€ routes/             # DÃ©finition des routes
â”‚   â”œâ”€â”€ interfaces/         # Types TypeScript
â”‚   â”œâ”€â”€ lib/                # Configurations (Prisma, Redis, Supabase)
â”‚   â”œâ”€â”€ utils/              # Utilitaires (logger, erreurs, etc.)
â”‚   â””â”€â”€ app.ts              # Application Express principale
â”œâ”€â”€ prisma/                 # SchÃ©ma et migrations base de donnÃ©es
â”œâ”€â”€ monitoring/             # Configuration Prometheus/Grafana
â”œâ”€â”€ docker-compose.yml      # Orchestration Docker
â”œâ”€â”€ Dockerfile             # Image Docker
â””â”€â”€ start.sh               # Script de dÃ©marrage automatisÃ©
```

## ğŸš€ Installation

### PrÃ©requis
- Node.js 18+
- PostgreSQL 13+
- Redis 6+
- Compte Supabase (authentification)

### DÃ©marrage rapide avec script automatisÃ©

```bash
# Cloner dans le dossier du microservice
cd metrics-microservice

# Lancer le script interactif
./start.sh
```

Le script vous guidera Ã  travers:
1. VÃ©rification de l'environnement
2. Installation des dÃ©pendances
3. Configuration de la base de donnÃ©es
4. Choix du mode de dÃ©marrage

### Installation manuelle

1. **Installation des dÃ©pendances**
   ```bash
   npm install
   ```

2. **Configuration des variables d'environnement**
   ```bash
   cp .env.example .env
   # Ã‰diter le fichier .env avec vos configurations
   ```

3. **Configuration de la base de donnÃ©es**
   ```bash
   npx prisma generate
   npx prisma db push
   ```

4. **DÃ©marrage en dÃ©veloppement**
   ```bash
   npm run dev
   ```

### DÃ©ploiement avec Docker

1. **Services principaux**
   ```bash
   docker-compose up -d --build
   ```

2. **Avec services d'administration (PgAdmin, Redis Commander)**
   ```bash
   docker-compose --profile admin up -d --build
   ```

3. **Avec monitoring (Prometheus, Grafana)**
   ```bash
   docker-compose --profile monitoring up -d --build
   ```

## ğŸ”§ Configuration

### Variables d'environnement essentielles

| Variable | Description | Exemple |
|----------|-------------|---------|
| `DATABASE_URL` | URL PostgreSQL | `postgresql://user:pass@localhost:5434/metrics` |
| `REDIS_HOST` | Serveur Redis | `localhost` |
| `REDIS_PORT` | Port Redis | `6381` |
| `SUPABASE_URL` | URL Supabase | `https://xxx.supabase.co` |
| `SUPABASE_ANON_KEY` | ClÃ© Supabase | `eyJ...` |
| `CACHE_TTL` | TTL cache (secondes) | `1800` |

### Configuration Docker

Les services Docker incluent:
- **metrics-app** (port 3003) : Application principale
- **metrics-db** (port 5434) : PostgreSQL avec optimisations
- **metrics-redis** (port 6381) : Redis avec persistance
- **metrics-pgadmin** (port 8084) : Administration DB (profile admin)
- **metrics-redis-commander** (port 8083) : Administration Redis (profile admin)
- **metrics-prometheus** (port 9091) : MÃ©triques (profile monitoring)
- **metrics-grafana** (port 3001) : Dashboards (profile monitoring)

## ğŸ“š API Endpoints

### MÃ©triques Dashboard

#### RÃ©cupÃ©rer les mÃ©triques principales
```http
GET /api/metrics/dashboard
Authorization: Bearer <token>
```

**RÃ©ponse:**
```json
{
  "success": true,
  "data": {
    "monthlyRevenue": 15000.00,
    "yearlyRevenue": 180000.00,
    "pendingInvoices": 5,
    "overdueInvoices": 2,
    "topCustomers": [
      {
        "customer_id": "uuid",
        "name": "Client A",
        "total_amount": 5000.00,
        "invoice_count": 12,
        "type": "company"
      }
    ],
    "invoiceStatusDistribution": [
      { "status": "paid", "_count": 45 },
      { "status": "pending", "_count": 5 }
    ],
    "quoteToInvoiceRatio": 0.75,
    "averagePaymentDelay": 15,
    "growthRate": 12.5
  }
}
```

### Analytics Revenus

#### Analyse des revenus par pÃ©riode
```http
GET /api/metrics/revenue?period=monthly&startDate=2024-01-01&endDate=2024-12-31
Authorization: Bearer <token>
```

### MÃ©triques Temps RÃ©el

#### DonnÃ©es en temps rÃ©el
```http
GET /api/metrics/realtime
Authorization: Bearer <token>
```

### Analytics Clients

#### Analyse des clients avec pagination
```http
GET /api/metrics/customers?page=1&limit=10&sortBy=lifetimeValue&sortOrder=desc
Authorization: Bearer <token>
```

### Analytics Produits

#### Performance des produits
```http
GET /api/metrics/products?page=1&limit=10&sortBy=totalRevenue
Authorization: Bearer <token>
```

### Rapports

#### GÃ©nÃ©rer un rapport personnalisÃ©
```http
POST /api/metrics/reports
Authorization: Bearer <token>
Content-Type: application/json

{
  "reportType": "revenue_report",
  "period": {
    "start": "2024-01-01",
    "end": "2024-12-31"
  },
  "format": "PDF",
  "filters": {
    "includeCharts": true,
    "customers": ["customer-1", "customer-2"]
  }
}
```

#### Statut d'un rapport
```http
GET /api/metrics/reports/{reportId}
Authorization: Bearer <token>
```

### Utilitaires

#### Invalider le cache
```http
DELETE /api/metrics/cache
Authorization: Bearer <token>
```

#### Health check
```http
GET /api/metrics/health
```

## ğŸ­ Base de DonnÃ©es

### ModÃ¨les principaux

Le microservice utilise les modÃ¨les du backend principal (Company, User, Customer, Invoice, Quote, Product) et ajoute des modÃ¨les spÃ©cialisÃ©s pour les mÃ©triques:

#### CompanyMetrics
MÃ©triques agrÃ©gÃ©es par entreprise et pÃ©riode
```sql
- total_revenue, invoices_count, quotes_count
- avg_invoice_amount, conversion_rate
- new_customers_count, active_customers_count
```

#### KPISnapshot
InstantanÃ©s des KPIs Ã  une date donnÃ©e
```sql
- monthly_revenue, yearly_revenue, mrr, arr
- churn_rate, customer_lifetime_value
- profit_margin, growth_rate
```

#### UserMetrics
MÃ©triques de productivitÃ© par utilisateur
```sql
- invoices_created, quotes_created, revenue_generated
- customers_acquired, login_count, productivity_score
```

#### CustomerMetrics
Analytics clients dÃ©taillÃ©es
```sql
- total_invoiced, total_paid, lifetime_value
- average_payment_delay, risk_score, churn_date
```

#### MetricAlert
Configuration des alertes automatiques
```sql
- metric_type, condition, threshold_value
- notification_emails, last_triggered
```

### Optimisations

- **Index** sur toutes les colonnes de filtrage frÃ©quent
- **Partitioning** par pÃ©riode pour les grandes tables
- **AgrÃ©gations** prÃ©-calculÃ©es via jobs cron
- **Cache Redis** pour les requÃªtes coÃ»teuses

## ğŸ“Š Monitoring et ObservabilitÃ©

### Logs StructurÃ©s
Logging avec Pino incluant:
```json
{
  "level": "info",
  "time": "2024-01-15T10:30:00.000Z",
  "service": "metrics-microservice",
  "requestId": "req-uuid",
  "userId": "user-uuid",
  "companyId": "company-uuid",
  "action": "dashboard_metrics_calculated",
  "duration": "250ms",
  "cacheHit": true
}
```

### MÃ©triques Prometheus
- Nombre de requÃªtes par endpoint
- Latence moyenne des requÃªtes
- Taux d'erreur par type
- Utilisation du cache Redis
- Performance des requÃªtes base de donnÃ©es

### Dashboards Grafana
- Vue d'ensemble du service
- Performance des APIs
- SantÃ© de la base de donnÃ©es
- MÃ©triques business en temps rÃ©el

### Health Checks
- **Endpoint** `/health` pour vÃ©rifications de base
- **Deep health check** avec tests de connectivitÃ©
- **Readiness probe** pour Kubernetes
- **Liveness probe** pour Docker

## ğŸ”’ SÃ©curitÃ©

### Authentification
- **Supabase Auth** pour tous les endpoints protÃ©gÃ©s
- **JWT validation** avec vÃ©rification des claims
- **Rate limiting** : 100 req/15min par IP
- **CORS** restrictif selon configuration

### Protection des DonnÃ©es
- **Anonymisation** des donnÃ©es sensibles dans les logs
- **Chiffrement** des donnÃ©es en cache
- **Validation** stricte des entrÃ©es utilisateur
- **Audit trail** des actions sensibles

### Autorisation
- **Isolation** par entreprise (company_id)
- **Permissions** basÃ©es sur les rÃ´les utilisateur
- **AccÃ¨s restreint** aux mÃ©triques par propriÃ©taire

## âš¡ Performance

### StratÃ©gies de Cache
```typescript
// Cache intelligent par couches
const cacheKey = `metrics:dashboard:${companyId}`;
const ttl = 30 * 60; // 30 minutes

// Invalidation automatique lors de changements
await invalidateCache(`metrics:*:${companyId}`);
```

### Optimisations de RequÃªtes
- **AgrÃ©gations** prÃ©-calculÃ©es en arriÃ¨re-plan
- **Pagination** efficace pour grandes datasets
- **Index** composites pour requÃªtes complexes
- **Connection pooling** pour PostgreSQL

### Mise Ã  l'Ã‰chelle
- **Clustering** Node.js pour utilisation multi-core
- **Redis Cluster** pour distribution du cache
- **Read replicas** PostgreSQL pour requÃªtes analytiques
- **Load balancing** avec health checks

## ğŸš¨ Troubleshooting

### ProblÃ¨mes Courants

**1. Erreur de connexion base de donnÃ©es**
```bash
# VÃ©rifier le service PostgreSQL
docker-compose ps metrics-db
docker-compose logs metrics-db

# Tester la connectivitÃ©
npx prisma db push
```

**2. Cache Redis indisponible**
```bash
# VÃ©rifier Redis
docker-compose ps metrics-redis
redis-cli -h localhost -p 6381 ping

# Nettoyer le cache
redis-cli -h localhost -p 6381 flushdb
```

**3. MÃ©triques incorrectes**
```bash
# Recalculer les agrÃ©gations
curl -X DELETE http://localhost:3003/api/metrics/cache \
  -H "Authorization: Bearer YOUR_TOKEN"

# VÃ©rifier les logs
docker-compose logs metrics-app
```

**4. Performance dÃ©gradÃ©e**
```bash
# Monitoring en temps rÃ©el
curl http://localhost:3003/api/metrics/health

# VÃ©rifier les mÃ©triques Prometheus
curl http://localhost:9091/metrics
```

### Logs et Diagnostic

**Niveaux de log disponibles:**
- `error` : Erreurs critiques uniquement
- `warn` : Avertissements et erreurs
- `info` : Informations gÃ©nÃ©rales (dÃ©faut)
- `debug` : DÃ©tails de dÃ©bogage

**Commandes utiles:**
```bash
# Logs en temps rÃ©el
docker-compose logs -f metrics-app

# Filtrer par niveau
docker-compose logs metrics-app | grep ERROR

# Stats Redis
redis-cli -h localhost -p 6381 info stats
```

## ğŸ”„ IntÃ©gration

### Depuis le Backend Principal

```typescript
// Client pour le microservice de mÃ©triques
const metricsClient = {
  baseURL: 'http://localhost:3003',
  
  async getDashboard(token: string, companyId: string) {
    const response = await fetch(`${this.baseURL}/api/metrics/dashboard`, {
      headers: { 
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      }
    });
    return response.json();
  },
  
  async invalidateCache(token: string) {
    await fetch(`${this.baseURL}/api/metrics/cache`, {
      method: 'DELETE',
      headers: { 'Authorization': `Bearer ${token}` }
    });
  }
};
```

### Webhooks et Ã‰vÃ©nements

Le microservice peut s'abonner aux Ã©vÃ©nements business:
```typescript
// Ã‰vÃ©nements Ã  Ã©couter pour mise Ã  jour des mÃ©triques
const EVENTS = {
  INVOICE_PAID: 'invoice.paid',
  QUOTE_ACCEPTED: 'quote.accepted',
  CUSTOMER_CREATED: 'customer.created',
  PRODUCT_SOLD: 'product.sold'
};
```

## ğŸ“– Exemples d'Utilisation

### Dashboard React

```typescript
import { useEffect, useState } from 'react';

const MetricsDashboard = () => {
  const [metrics, setMetrics] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const fetchMetrics = async () => {
      try {
        const response = await fetch('/api/metrics/dashboard', {
          headers: {
            'Authorization': `Bearer ${userToken}`
          }
        });
        const data = await response.json();
        setMetrics(data.data);
      } catch (error) {
        console.error('Erreur metrics:', error);
      } finally {
        setLoading(false);
      }
    };

    fetchMetrics();
    // Refresh toutes les 5 minutes
    const interval = setInterval(fetchMetrics, 5 * 60 * 1000);
    return () => clearInterval(interval);
  }, []);

  if (loading) return <div>Chargement des mÃ©triques...</div>;

  return (
    <div className="metrics-dashboard">
      <div className="kpi-cards">
        <KPICard 
          title="Chiffre d'Affaires Mensuel"
          value={metrics.monthlyRevenue}
          format="currency"
          trend={metrics.growthRate}
        />
        <KPICard 
          title="Factures en Attente"
          value={metrics.pendingInvoices}
          format="number"
        />
      </div>
      
      <div className="charts">
        <RevenueChart data={metrics.revenueAnalytics} />
        <CustomerChart data={metrics.topCustomers} />
      </div>
    </div>
  );
};
```

### GÃ©nÃ©ration de Rapports

```typescript
const generateMonthlyReport = async () => {
  // Lancer la gÃ©nÃ©ration
  const response = await fetch('/api/metrics/reports', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${token}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      reportType: 'revenue_report',
      period: {
        start: '2024-01-01',
        end: '2024-01-31'
      },
      format: 'PDF',
      filters: {
        includeCharts: true,
        includeDetails: true
      }
    })
  });
  
  const { data: report } = await response.json();
  
  // Polling du statut
  const checkStatus = async () => {
    const statusResponse = await fetch(`/api/metrics/reports/${report.id}`);
    const { data: status } = await statusResponse.json();
    
    if (status.status === 'completed') {
      // TÃ©lÃ©charger le rapport
      window.open(status.downloadUrl);
    } else if (status.status === 'failed') {
      console.error('GÃ©nÃ©ration Ã©chouÃ©e:', status.error);
    } else {
      // Retry dans 2 secondes
      setTimeout(checkStatus, 2000);
    }
  };
  
  checkStatus();
};
```

## ğŸ¤ Contribution

1. **Fork** le projet
2. **CrÃ©er** une branche feature (`git checkout -b feature/amazing-analytics`)
3. **Commit** les changements (`git commit -m 'Add amazing analytics'`)
4. **Push** vers la branche (`git push origin feature/amazing-analytics`)
5. **Ouvrir** une Pull Request

### Standards de Code

- **TypeScript** strict mode activÃ©
- **ESLint** et **Prettier** pour le formatage
- **Tests** unitaires pour les services critiques
- **Documentation** JSDoc pour les fonctions publiques
- **Logs** structurÃ©s pour toutes les opÃ©rations

## ğŸ“„ Licence

PropriÃ©taire - ZenBilling Â© 2024

---

## ğŸ†˜ Support

- **Documentation** : Ce README et commentaires inline
- **Logs** : Consultez les logs de l'application
- **Monitoring** : Dashboards Grafana disponibles
- **Contact** : Ã‰quipe ZenBilling

**Ports utilisÃ©s:**
- `3003` : Application principale
- `5434` : PostgreSQL
- `6381` : Redis
- `8084` : PgAdmin (profile admin)
- `8083` : Redis Commander (profile admin)
- `9091` : Prometheus (profile monitoring)
- `3001` : Grafana (profile monitoring) 